{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNziViP9NpDdJLgisy55AZ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Google drive mount"],"metadata":{"id":"mb-tz_qxcnQ1"}},{"cell_type":"code","source":["# google drive에 있는 데이터를 사용하기 위해 접근\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8-X0kzZciv2","executionInfo":{"status":"ok","timestamp":1664855706724,"user_tz":-540,"elapsed":25072,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"eff070c1-8046-42b9-f114-03377dac38a2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Test"],"metadata":{"id":"2O9-aGinSOZ8"}},{"cell_type":"code","source":["# tensorflow를 import 하고, 현재 colab에서 gpu 구동이 되고 있는지 테스트 하는 코드\n","# Found GPU at: /device:GPU ~ 가 뜨면 성공\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4xTUSMUSOAJ","executionInfo":{"status":"ok","timestamp":1664855715487,"user_tz":-540,"elapsed":6111,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"8cda1e78-a3ad-4107-88e5-92b73becf54f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"markdown","source":["# library import"],"metadata":{"id":"lF368LD2ctTF"}},{"cell_type":"code","source":["import nltk, random, numpy as np, pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras import optimizers\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, roc_curve, roc_auc_score, mean_squared_error, r2_score\n","\n","import matplotlib.pyplot as plt\n","\n","!pip install lime\n","from lime.lime_text import LimeTextExplainer"],"metadata":{"id":"BuEBFDSUbpif","executionInfo":{"status":"ok","timestamp":1664855729213,"user_tz":-540,"elapsed":7966,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"558639c7-57f7-43ec-b020-4364f8fbc745"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[K     |████████████████████████████████| 275 kB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.64.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.9.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.3.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=da16eb5753502289d3ea7a622d58dfbec30ab95b45dc1d2ac65f3ece1738bc9a\n","  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n"]}]},{"cell_type":"markdown","source":["# CLS/REG Data load"],"metadata":{"id":"DQN9w8Micwuu"}},{"cell_type":"code","source":["# 경로 저장 \n","cls_data_path = '/content/drive/MyDrive/숨고/류재용님(transformer 구현)/Training_data_cls.tsv' \n","reg_data_path = '/content/drive/MyDrive/숨고/류재용님(transformer 구현)/Training_data_reg.tsv'\n","\n","# 데이터 불러오기\n","train_cls = pd.read_csv(cls_data_path, sep=\"\\t\")\n","train_reg = pd.read_csv(reg_data_path, sep=\"\\t\")\n","\n","train_cls.head()"],"metadata":{"id":"9BmYb4sdb9Ga","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664855742369,"user_tz":-540,"elapsed":2451,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"6b3f54b0-f18c-4c16-8905-a8b7bebf3880"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Seq  Label\n","0  WSHPSFYPFR      1\n","1  WLMACFFVFR      0\n","2  WTVDGLYEYD      1\n","3  WRATSFYLNT      0\n","4  WRSIAFFMFA      0"],"text/html":["\n","  <div id=\"df-09e12a5c-26ba-4263-a840-f426178258b5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Seq</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WSHPSFYPFR</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>WLMACFFVFR</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WTVDGLYEYD</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>WRATSFYLNT</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>WRSIAFFMFA</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e12a5c-26ba-4263-a840-f426178258b5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-09e12a5c-26ba-4263-a840-f426178258b5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-09e12a5c-26ba-4263-a840-f426178258b5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 일부 데이터 추출\n","train_cls_sample = train_cls.iloc[:5000,:]\n","x_cls_train_sample = train_cls[['Seq']]\n","y_cls_train_sample = train_cls[['Label']]\n","train_reg_sample = train_reg.iloc[:5000,:]\n","x_reg_train_sample = train_reg[['Seq']]\n","y_reg_train_sample = train_reg[['Label']]"],"metadata":{"id":"Egb9J0NvIr8f","executionInfo":{"status":"ok","timestamp":1664855931914,"user_tz":-540,"elapsed":6,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Text Preprocessing"],"metadata":{"id":"XbATs76ftLDp"}},{"cell_type":"code","source":["vocab = ['A', 'C', 'D', 'E', \n","         'F', 'G', 'H', 'I', \n","         'K', 'L', 'M', 'N', \n","         'P', 'Q', 'R', 'S',\n","         'T', 'V', 'W', 'Y']\n","\n","def preprocessing(text):\n","    text = list(tuple(text))\n","    tokens = [token for token in text if token in vocab]\n","    return tokens\n","\n","x_cls_train_sample['Seq_processed'] = x_cls_train_sample['Seq'].apply(lambda x : preprocessing(x))\n","x_reg_train_sample['Seq_processed'] = x_reg_train_sample['Seq'].apply(lambda x : preprocessing(x))"],"metadata":{"id":"OTWrsPBQvTpV","executionInfo":{"status":"ok","timestamp":1664855935246,"user_tz":-540,"elapsed":460,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def text_to_sequence(text, max_len):\n","    \n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(text)\n","    text_sequence = tokenizer.texts_to_sequences(text)\n","    vocab_size = len(tokenizer.word_index)\n","    print('vocab_size : ', vocab_size)\n","    return np.array(text_sequence), vocab_size, tokenizer\n","\n","x_train_cls, vocab_size, cls_tokenizer = text_to_sequence(x_cls_train_sample['Seq_processed'], max_len = 10)\n","x_train_reg, vocab_size, reg_tokenizer = text_to_sequence(x_reg_train_sample['Seq_processed'], max_len = 10)\n","\n","print(x_train_cls.shape)\n","print(x_train_reg.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKJJ0JWDsWIS","executionInfo":{"status":"ok","timestamp":1664856011032,"user_tz":-540,"elapsed":1745,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"40d48e31-3979-444d-c997-9a84e6bab357"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab_size :  20\n","vocab_size :  20\n","(36391, 10)\n","(36391, 10)\n"]}]},{"cell_type":"markdown","source":["# Transformer Architecture \n"],"metadata":{"id":"PO-i6nFuNNZs"}},{"cell_type":"markdown","source":["#### Transformer block as a layer\n","- Self Attention, Normalization, and feed-forward networks\n","- (https://keras.io/examples/nlp/text_classification_with_transformer/)"],"metadata":{"id":"GL06tU9e10Rj"}},{"cell_type":"code","source":["class TransformerBlock(layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, hidden_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(hidden_dim, activation=\"relu\"), layers.Dense(embedding_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n"],"metadata":{"id":"qAzCTsFqMzMh","executionInfo":{"status":"ok","timestamp":1664856321798,"user_tz":-540,"elapsed":527,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["#### Embedding & Position\n","- In Transformer-based networks, we need to include positional information of the tokens in the embeddings."],"metadata":{"id":"mWD26NCn1sIV"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embedding_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embedding_dim)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"metadata":{"id":"BND8ZKAz1rtK","executionInfo":{"status":"ok","timestamp":1664856322260,"user_tz":-540,"elapsed":2,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["#### Classification fine tuning"],"metadata":{"id":"s_mBFEpC154u"}},{"cell_type":"code","source":["embedding_dim = 32  # Embedding size for each token\n","num_heads = 2  # Number of attention heads\n","hidden_dim = 32  # Hidden layer size in feed forward network inside transformer\n","vocab_size = 20 # total vocab size\n","maxlen = 10  # Only consider the last 10 words of each row\n","learning_rate = 0.0001 # learning rate\n","batch_size = 128\n","epochs = 100\n","\n","inputs = layers.Input(shape=(maxlen,))\n","embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embedding_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embedding_dim, num_heads, hidden_dim)\n","x = transformer_block(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"relu\")(x)\n","x = layers.Dropout(0.1)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwT-4gdR1rvI","executionInfo":{"status":"ok","timestamp":1664856352856,"user_tz":-540,"elapsed":1100,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"e6bd62be-aba5-4f12-bfec-89e8bae3edc3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," token_and_position_embeddin  (None, 10, 32)           960       \n"," g (TokenAndPositionEmbeddin                                     \n"," g)                                                              \n","                                                                 \n"," transformer_block (Transfor  (None, 10, 32)           10656     \n"," merBlock)                                                       \n","                                                                 \n"," global_average_pooling1d (G  (None, 32)               0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dropout_2 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 20)                660       \n","                                                                 \n"," dropout_3 (Dropout)         (None, 20)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 12,297\n","Trainable params: 12,297\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# pretrained model load\n","model.load_weights(\"/content/drive/MyDrive/숨고/류재용님(transformer 구현)/cls_weights.best.hdf5\")"],"metadata":{"id":"93_eD3MJK8fm","executionInfo":{"status":"ok","timestamp":1664857321450,"user_tz":-540,"elapsed":470,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# 전체 layer에 대해 fine tuning\n","for layer in model.layers:\n","    layer.trainable = True"],"metadata":{"id":"UUq2kBRaLvP2","executionInfo":{"status":"ok","timestamp":1664857321957,"user_tz":-540,"elapsed":5,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["optimizer = optimizers.Adam(learning_rate=learning_rate)\n","model.compile(optimizer=\"adam\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=15)\n","\n","history = model.fit(x_train_cls,\n","                    y_cls_train_sample,\n","                    callbacks=[es],\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.1,\n","                    shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_4Mq8xzNX5S","executionInfo":{"status":"ok","timestamp":1664857388984,"user_tz":-540,"elapsed":67031,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"52bc071b-571c-44e3-d9cb-02cd2187c0de"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","256/256 [==============================] - 4s 8ms/step - loss: 1.4293 - accuracy: 0.8390 - val_loss: 1.0442 - val_accuracy: 0.7945\n","Epoch 2/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.7650 - accuracy: 0.7983 - val_loss: 1.0161 - val_accuracy: 0.6860\n","Epoch 3/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.6136 - accuracy: 0.7903 - val_loss: 0.4519 - val_accuracy: 0.8420\n","Epoch 4/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.5474 - accuracy: 0.8106 - val_loss: 0.4427 - val_accuracy: 0.8516\n","Epoch 5/100\n","256/256 [==============================] - 2s 10ms/step - loss: 0.5363 - accuracy: 0.8212 - val_loss: 0.4305 - val_accuracy: 0.8624\n","Epoch 6/100\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5170 - accuracy: 0.8275 - val_loss: 0.4165 - val_accuracy: 0.8604\n","Epoch 7/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.5106 - accuracy: 0.8211 - val_loss: 0.4273 - val_accuracy: 0.8560\n","Epoch 8/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4813 - accuracy: 0.8323 - val_loss: 0.4191 - val_accuracy: 0.8514\n","Epoch 9/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.6797 - accuracy: 0.7716 - val_loss: 0.4569 - val_accuracy: 0.8299\n","Epoch 10/100\n","256/256 [==============================] - 2s 8ms/step - loss: 0.4774 - accuracy: 0.8012 - val_loss: 0.4325 - val_accuracy: 0.8426\n","Epoch 11/100\n","256/256 [==============================] - 2s 10ms/step - loss: 0.4535 - accuracy: 0.8153 - val_loss: 0.4214 - val_accuracy: 0.8475\n","Epoch 12/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4532 - accuracy: 0.8190 - val_loss: 0.4101 - val_accuracy: 0.8527\n","Epoch 13/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4527 - accuracy: 0.8274 - val_loss: 0.4100 - val_accuracy: 0.8560\n","Epoch 14/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4520 - accuracy: 0.8344 - val_loss: 0.4290 - val_accuracy: 0.8453\n","Epoch 15/100\n","256/256 [==============================] - 2s 8ms/step - loss: 0.4558 - accuracy: 0.8245 - val_loss: 0.3937 - val_accuracy: 0.8481\n","Epoch 16/100\n","256/256 [==============================] - 2s 8ms/step - loss: 0.4136 - accuracy: 0.8211 - val_loss: 0.3957 - val_accuracy: 0.8541\n","Epoch 17/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4155 - accuracy: 0.8353 - val_loss: 0.3643 - val_accuracy: 0.8679\n","Epoch 18/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4580 - accuracy: 0.8206 - val_loss: 0.4863 - val_accuracy: 0.7602\n","Epoch 19/100\n","256/256 [==============================] - 2s 9ms/step - loss: 0.4740 - accuracy: 0.7714 - val_loss: 0.4213 - val_accuracy: 0.8148\n","Epoch 20/100\n","256/256 [==============================] - 2s 8ms/step - loss: 0.4188 - accuracy: 0.8126 - val_loss: 0.3756 - val_accuracy: 0.8484\n","Epoch 21/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4253 - accuracy: 0.8097 - val_loss: 0.4031 - val_accuracy: 0.8429\n","Epoch 22/100\n","256/256 [==============================] - 2s 9ms/step - loss: 0.4087 - accuracy: 0.8221 - val_loss: 0.3650 - val_accuracy: 0.8552\n","Epoch 23/100\n","256/256 [==============================] - 3s 11ms/step - loss: 0.3984 - accuracy: 0.8290 - val_loss: 0.3576 - val_accuracy: 0.8615\n","Epoch 24/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.3890 - accuracy: 0.8321 - val_loss: 0.3524 - val_accuracy: 0.8662\n","Epoch 25/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4749 - accuracy: 0.7931 - val_loss: 0.4218 - val_accuracy: 0.8187\n","Epoch 26/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4290 - accuracy: 0.8052 - val_loss: 0.3802 - val_accuracy: 0.8431\n","Epoch 27/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4183 - accuracy: 0.8153 - val_loss: 0.3797 - val_accuracy: 0.8409\n","Epoch 28/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4215 - accuracy: 0.8270 - val_loss: 0.3779 - val_accuracy: 0.8495\n","Epoch 29/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4067 - accuracy: 0.8235 - val_loss: 0.3636 - val_accuracy: 0.8538\n","Epoch 30/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4126 - accuracy: 0.8183 - val_loss: 0.3598 - val_accuracy: 0.8495\n","Epoch 31/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.3981 - accuracy: 0.8312 - val_loss: 0.3621 - val_accuracy: 0.8580\n","Epoch 32/100\n","256/256 [==============================] - 2s 7ms/step - loss: 0.4719 - accuracy: 0.7827 - val_loss: 0.3929 - val_accuracy: 0.8396\n","Epoch 32: early stopping\n"]}]},{"cell_type":"code","source":["model.save_weights(\"/content/drive/MyDrive/숨고/류재용님(transformer 구현)/cls_weights.fine_tuning.hdf5\" )"],"metadata":{"id":"8gGkpD_n6q83","executionInfo":{"status":"ok","timestamp":1664857389445,"user_tz":-540,"elapsed":7,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["#### Regression fine tuning"],"metadata":{"id":"oZ793FVON9WW"}},{"cell_type":"code","source":["embedding_dim = 32  # Embedding size for each token\n","num_heads = 2  # Number of attention heads\n","hidden_dim = 32  # Hidden layer size in feed forward network inside transformer\n","vocab_size = 20 # total vocab size\n","maxlen = 10  # Only consider the last 10 words of each row\n","learning_rate = 0.0001 # learning rate\n","batch_size = 128\n","epochs = 100\n","\n","inputs = layers.Input(shape=(maxlen,))\n","embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embedding_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embedding_dim, num_heads, hidden_dim)\n","x = transformer_block(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"relu\")(x)\n","x = layers.Dropout(0.1)(x)\n","outputs = layers.Dense(1)(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xdg3FomhOLrA","executionInfo":{"status":"ok","timestamp":1664857391210,"user_tz":-540,"elapsed":740,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"3bf8eae1-2914-41e3-8bd4-1e0b658f6662"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," token_and_position_embeddin  (None, 10, 32)           960       \n"," g_2 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," transformer_block_2 (Transf  (None, 10, 32)           10656     \n"," ormerBlock)                                                     \n","                                                                 \n"," global_average_pooling1d_2   (None, 32)               0         \n"," (GlobalAveragePooling1D)                                        \n","                                                                 \n"," dropout_10 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_10 (Dense)            (None, 20)                660       \n","                                                                 \n"," dropout_11 (Dropout)        (None, 20)                0         \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 12,297\n","Trainable params: 12,297\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# pretrained model load\n","model.load_weights(\"/content/drive/MyDrive/숨고/류재용님(transformer 구현)/reg_weights.best.hdf5\")"],"metadata":{"id":"t1ZNmYs_OAea","executionInfo":{"status":"ok","timestamp":1664857391210,"user_tz":-540,"elapsed":9,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# 전체 layer에 대해 fine tuning\n","for layer in model.layers:\n","    layer.trainable = True"],"metadata":{"id":"rZKz17JEOnFO","executionInfo":{"status":"ok","timestamp":1664857391211,"user_tz":-540,"elapsed":9,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["optimizer = optimizers.Adam(learning_rate=learning_rate)\n","model.compile(optimizer=\"adam\",\n","              loss=\"mse\")\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n","\n","history = model.fit(x_train_reg,\n","                    y_reg_train_sample,\n","                    callbacks=[es],\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.1,\n","                    shuffle=True)"],"metadata":{"id":"E59CrGT4LREK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664857422145,"user_tz":-540,"elapsed":30943,"user":{"displayName":"민재홍","userId":"10669517274837738962"}},"outputId":"45eab710-eecd-4dae-a1c5-7104156e3fdc"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","256/256 [==============================] - 4s 8ms/step - loss: 1.5877e-04 - val_loss: 3.3703e-06\n","Epoch 2/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.5278e-04 - val_loss: 2.0822e-05\n","Epoch 3/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.4218e-04 - val_loss: 4.9836e-06\n","Epoch 4/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.4524e-04 - val_loss: 8.7178e-06\n","Epoch 5/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.4296e-04 - val_loss: 2.3228e-05\n","Epoch 6/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.3982e-04 - val_loss: 7.6704e-06\n","Epoch 7/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.3317e-04 - val_loss: 4.3869e-06\n","Epoch 8/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.3427e-04 - val_loss: 4.6702e-06\n","Epoch 9/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.3029e-04 - val_loss: 1.7921e-05\n","Epoch 10/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2696e-04 - val_loss: 1.1881e-05\n","Epoch 11/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2798e-04 - val_loss: 8.1708e-06\n","Epoch 12/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2393e-04 - val_loss: 6.2586e-06\n","Epoch 13/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2055e-04 - val_loss: 8.8386e-06\n","Epoch 14/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2071e-04 - val_loss: 7.4393e-06\n","Epoch 15/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2277e-04 - val_loss: 1.0594e-05\n","Epoch 16/100\n","256/256 [==============================] - 2s 7ms/step - loss: 1.2174e-04 - val_loss: 8.5323e-06\n","Epoch 16: early stopping\n"]}]},{"cell_type":"code","source":["model.save_weights(\"/content/drive/MyDrive/숨고/류재용님(transformer 구현)/reg_weights.fine_tuning.hdf5\" )"],"metadata":{"id":"eov53MTPLRBi","executionInfo":{"status":"ok","timestamp":1664857422146,"user_tz":-540,"elapsed":19,"user":{"displayName":"민재홍","userId":"10669517274837738962"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ggv0N8r8O0wr"},"execution_count":null,"outputs":[]}]}